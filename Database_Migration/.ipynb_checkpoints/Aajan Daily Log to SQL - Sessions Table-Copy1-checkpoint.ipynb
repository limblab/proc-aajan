{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5e6cd1",
   "metadata": {},
   "source": [
    "Before adding data into tables, make sure to install necessary drivers:\n",
    "\n",
    "- sudo apt install libmysqlclient mysql-client-core (linux)\n",
    "- brew install mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ea3e1",
   "metadata": {},
   "source": [
    "Here I extract the data that is necessary to populate the sessions and table. The sessions table requires the following fields (bolded ones still need to be done):\n",
    "\n",
    "- day_key - DONE\n",
    "- rec_time - DONE \n",
    "- **sessions_key - sessions table ?**\n",
    "- paper_key - #leave nan - reference for which papers have used this data\n",
    "- **behavior_notes - daily log** behavioral notes from daily log should go into days table; behavioral notes from data log should go into sessions table (this has behvaior information for each session)\n",
    "- **behavior_quality - daily log**\n",
    "- **other_notes - daily log**\n",
    "- task_id - DONE (*note: ignore all task-related data from ['digital_events']['UnparsedData'] for FR tasks*)\n",
    "- **lab_num - daily log**\n",
    "- duration - DONE (now in basic_header)\n",
    "- numChannels - DONE\n",
    "- hasTriggers - #leave nan - if you don't fill in it should be nan\n",
    "- hasChaoticLoad - #leave nan - if you don't fill in it should be nan\n",
    "- hasBumps - DONE\n",
    "- numTrials - DONE\n",
    "- numReward - DONE\n",
    "- numAbort - DONE\n",
    "- numFail - DONE\n",
    "- numIncomplete - DONE\n",
    "- reward_size - #leave blank for now, fill in as we go through daily logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2baf6",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "- The daily logs only have one entry per day, but there may be multiple nevs for a single day. Should I assign the daily log info for a single day to multiple entries?\n",
    "    - yes\n",
    "- Not all files have digital_events, where unparsed hexidecimal data is stored. Anywhere else to get this?\n",
    "    - Can ignore task data for FR \n",
    "- \"strides is incompatible with shape of requested array and size of buffer\" error when opening 20200213_Greyson_Cage_016016.nev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f69e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from os import path, system\n",
    "import sys\n",
    "from sys import platform\n",
    "import glob\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "# import xml.etree.ElementTree as ET\n",
    "import time\n",
    "# from PyQt5.QtWidgets import QFileDialog\n",
    "\n",
    "# brpylib is the module that contains functions/classes that allow us to open and extract data from .nev and .nsx files\n",
    "# from Python_Utilities import brpylib\n",
    "# from Python_Utilities import brMiscFxns\n",
    "from Python_Utilities_Kev import brpylib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731901c1",
   "metadata": {},
   "source": [
    "# Daily Log Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4ff5b",
   "metadata": {},
   "source": [
    "- behavior_notes - daily log\n",
    "- behavior_quality - daily log\n",
    "- other_notes - daily log\n",
    "- lab num - daily log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16378554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.google.com/spreadsheets/d/1TOp_K1enCerQ4b1jbn5eiZAMmNLJRv2pFFHWA3Ot7w8/export?gid=506541297&format=csv&sheet=DailyLog\n"
     ]
    }
   ],
   "source": [
    "# Using a google sheet\n",
    "sheetName = \"DailyLog\"\n",
    "# file_id is the portion after the \"d\" in the URL\n",
    "file_id = \"1TOp_K1enCerQ4b1jbn5eiZAMmNLJRv2pFFHWA3Ot7w8\"\n",
    "gid1 = \"506541297\"\n",
    "gid2 = \"364050870\"\n",
    "dailylog_sheet = f\"https://docs.google.com/spreadsheets/d/{file_id}/export?gid={gid1}&format=csv&sheet={sheetName}\"\n",
    "datalog_sheet = f\"https://docs.google.com/spreadsheets/d/{file_id}/export?gid={gid2}&format=csv&sheet={sheetName}\"\n",
    "\n",
    "print(dailylog_sheet)\n",
    "\n",
    "dailylog = pd.read_csv(dailylog_sheet)\n",
    "datalog = pd.read_csv(datalog_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660fd7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 23 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Unnamed: 0                    999 non-null    object \n",
      " 1   Date                          992 non-null    object \n",
      " 2   Weight                        68 non-null     object \n",
      " 3   Start time                    62 non-null     object \n",
      " 4   End time                      39 non-null     object \n",
      " 5   H2O (lab)                     82 non-null     float64\n",
      " 6   H20 (bottle)                  56 non-null     float64\n",
      " 7   H2O (total)                   375 non-null    float64\n",
      " 8   Avg H2O intake                62 non-null     float64\n",
      " 9   Required Daily                29 non-null     float64\n",
      " 10  Required Average              29 non-null     float64\n",
      " 11  Pulse size (reg, jackpot, %)  54 non-null     object \n",
      " 12  Reward                        28 non-null     object \n",
      " 13  Abort                         4 non-null      float64\n",
      " 14  Fail                          14 non-null     float64\n",
      " 15  Incompl                       0 non-null      float64\n",
      " 16  Time doing task               314 non-null    object \n",
      " 17  Lab no.                       52 non-null     float64\n",
      " 18  Person running                70 non-null     object \n",
      " 19  Behavioral Notes              54 non-null     object \n",
      " 20  Health Notes                  37 non-null     object \n",
      " 21  Cleaned                       18 non-null     object \n",
      " 22  Other Notes                   27 non-null     object \n",
      "dtypes: float64(10), object(13)\n",
      "memory usage: 179.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dailylog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6440afcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Day                     37 non-null     object \n",
      " 1   Date                    37 non-null     object \n",
      " 2   File prefix             15 non-null     object \n",
      " 3   File #                  22 non-null     object \n",
      " 4   Task                    22 non-null     object \n",
      " 5   # of targs              3 non-null      float64\n",
      " 6   Sorting file name       0 non-null      float64\n",
      " 7   Unnamed: 7              0 non-null      float64\n",
      " 8   File length (min)       18 non-null     float64\n",
      " 9   Rwrds                   3 non-null      float64\n",
      " 10  Aborts                  0 non-null      float64\n",
      " 11  Fails                   0 non-null      float64\n",
      " 12  Incmpl                  0 non-null      float64\n",
      " 13  Successful experiment?  11 non-null     object \n",
      " 14  Comments                10 non-null     object \n",
      "dtypes: float64(8), object(7)\n",
      "memory usage: 6.3+ KB\n"
     ]
    }
   ],
   "source": [
    "datalog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74872de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Start time</th>\n",
       "      <th>End time</th>\n",
       "      <th>H2O (lab)</th>\n",
       "      <th>H20 (bottle)</th>\n",
       "      <th>H2O (total)</th>\n",
       "      <th>Avg H2O intake</th>\n",
       "      <th>Required Daily</th>\n",
       "      <th>...</th>\n",
       "      <th>Abort</th>\n",
       "      <th>Fail</th>\n",
       "      <th>Incompl</th>\n",
       "      <th>Time doing task</th>\n",
       "      <th>Lab no.</th>\n",
       "      <th>Person running</th>\n",
       "      <th>Behavioral Notes</th>\n",
       "      <th>Health Notes</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Other Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon</td>\n",
       "      <td>2/8/21</td>\n",
       "      <td>10.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue</td>\n",
       "      <td>2/9/21</td>\n",
       "      <td>10.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed</td>\n",
       "      <td>2/10/21</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu</td>\n",
       "      <td>2/11/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri</td>\n",
       "      <td>2/12/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0     Date Weight Start time End time  H2O (lab)  H20 (bottle)  \\\n",
       "0        Mon   2/8/21  10.18        NaN      NaN        NaN         400.0   \n",
       "1        Tue   2/9/21  10.38        NaN      NaN        NaN         200.0   \n",
       "2        Wed  2/10/21  10.30      10:10      NaN        NaN           NaN   \n",
       "3        Thu  2/11/21    NaN        NaN      NaN        NaN           NaN   \n",
       "4        Fri  2/12/21    NaN        NaN      NaN        NaN           NaN   \n",
       "\n",
       "   H2O (total)  Avg H2O intake  Required Daily  ...  Abort Fail Incompl  \\\n",
       "0        400.0             NaN           101.8  ...    NaN  NaN     NaN   \n",
       "1        200.0             NaN           103.8  ...    NaN  NaN     NaN   \n",
       "2          NaN             NaN           103.0  ...    NaN  NaN     NaN   \n",
       "3          NaN             NaN             NaN  ...    NaN  NaN     NaN   \n",
       "4          NaN             NaN             NaN  ...    NaN  NaN     NaN   \n",
       "\n",
       "   Time doing task  Lab no.  Person running Behavioral Notes  Health Notes  \\\n",
       "0              NaN      NaN              KD              NaN           NaN   \n",
       "1              NaN      NaN              KD              NaN           NaN   \n",
       "2              NaN      NaN              KD              NaN           NaN   \n",
       "3              NaN      NaN              KD              NaN           NaN   \n",
       "4              NaN      NaN              KD              NaN           NaN   \n",
       "\n",
       "  Cleaned Other Notes  \n",
       "0     NaN         NaN  \n",
       "1     NaN         NaN  \n",
       "2     NaN         NaN  \n",
       "3     NaN         NaN  \n",
       "4     NaN         NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e75bf",
   "metadata": {},
   "source": [
    "# Nev File Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6a41ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pancake_20K3\n",
      "/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data\n",
      "93 88\n"
     ]
    }
   ],
   "source": [
    "cerebus_data_dict = {}\n",
    "base_dir = '/Volumes/L_MillerLab/data/'\n",
    "for monkey in sorted(os.listdir(base_dir)):\n",
    "#     if monkey not in ['.DS_Store','archive','Backed_up_data', 'Behavior','chewie-delete','CompiledCOFiles','DeepLabCutVids','DLC_models','DPZ','FSMIT_DataRestore_03172021', 'Han_13B1_target','IMU','Jarvis','Jango_redo','Jango_target_redo','LoadCell','Mihili_12A3_target','OldCerebusTest','Rats','Rats_target','Test data','Thumbs.db']:\n",
    "    if monkey == 'Pancake_20K3':\n",
    "        print(monkey)\n",
    "        cerebus_data_dict[monkey] = {}\n",
    "        monkey_path = os.path.join(base_dir, monkey)\n",
    "        x = [i for i in os.listdir(monkey_path) if 'cerebus' in i.lower()]\n",
    "        if len(x) != 0:\n",
    "            cerebus_path = os.path.join(monkey_path, x[0])\n",
    "        else:\n",
    "            cerebus_path = monkey_path\n",
    "        print(cerebus_path)\n",
    "        nev_list = glob.glob(f\"{cerebus_path}/*/*.nev\")\n",
    "        nsx_list = glob.glob(f\"{cerebus_path}/*/*.ns*\")\n",
    "        print(len(nev_list), len(nsx_list))\n",
    "        cerebus_data_dict[monkey]['nev_list'] = nev_list\n",
    "        cerebus_data_dict[monkey]['nsx_list'] = nsx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0553d148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20211214/20211214_Pancake__FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221103/20221103_Pancake_WI_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20230214/20230214_Pancake_WM_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20230214/20230214_Pancake_WM_003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20230214/20230214_Pancake_WM_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210828/20210828_Pancake__FR_.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220921/20220921_Pancake_PG_Post_Con_03.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220921/20220921_Pancake_PG_Pre_Con_02.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220921/20220921_Pancake_WS_Pre_Con_01.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220921/20220921_Pancake_WS_Post_Con_04.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220920/20220920_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220920/20220920_Pancake_FR_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220920/20220920_Pancake_FR_003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220920/20220920_Pancake_FR_005.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220920/20220920_Pancake_FR_004.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220121/20220121_Pancake_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220106/20220106_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220103/20220103_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220103/20220103_Pancake_FR_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210826/20210826_Pancake__FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221102/20221102_Pancke_PG_PreCyp_.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221102/20221102_Pancke_PG_PostCyp_.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210917/20210917_Pancake_PG_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210917/20210917_Pancake_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20230216/20230216_Pancake_WM_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20230216/20230216_Pancake_WM_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220917/20220917_Pancake_FR_004.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220917/20220917_Pancake_FR_003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220917/20220917_Pancake_FR_005.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210823/20210823_Pancake20K2_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210913/20210913_Pancake_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220916/20220916_Pancake_WS_Post_Cyp002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220916/20220916_Pancake_WS_Pre_Cyp001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220916/20220916_Pancake_PG_Pre_Cyp004.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220916/20220916_Pancake_PG_Pre_Cyp002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220916/20220916_Pancake_PG_Pre_Cyp003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220916/20220916_Pancake_PG_Post_Cyp001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221027/20221027_Pancake_PG_01.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210831/20210831_Pancake_KG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221221/20221221_1602_Pancake_WS_003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221221/20221221_1613_Pancake_WS_004.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221221/20221221_Pancake_WM_HandControl_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221221/20221221_Pancake_WM_HandControl_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220623/20220623_Pancake_FR_001-s.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220623/20220623_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220107/20220107_Pancake_FR_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220107/20220107_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220124/20220124_Pancake_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220222/20220222_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220222/20220222_Pancake_FR_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221001/20221001_Pancake_EMGtest001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220915/20220915_Pancake_FR_003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220915/20220915_Pancake_FR_004.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220915/20220915_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220915/20220915_Pancake_FR_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220915/20220915_Pancake_FR_004-01-s.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210911/20210911_Pancake_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210920/20210920_Pancake_KG_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210920/20210920_Pancake_KG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221219/20221219_Pancake_WM_HandControl_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221028/20221028_Pancake_PG_01.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20211115/20211115_Pancake__FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220907/20220907_Pancake_PG_Post_Caff_05.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220907/20220907_Pancake_WS_Pre_Caff_02.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220907/20220907_Pancake_PG_Pre_Caff_01.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220907/20220907_Pancake_PG_Post_Caff_04.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220907/20220907_Pancake_WS_Post_Caff_03.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221213/20221213_Pancake_WM_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221213/20221213_1412_Pancake_WM_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221213/20221213_1425_Pancake_WM003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210821/20210821_Pancake_PG_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20210821/20210821_Pancake_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220104/20220104_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221201/20221201_Pancake_WM_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221201/20221201_Pancake_WM_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220628/20220628_Pancake_FR_003-s.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220628/20220628_Pancake_FR_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220628/20220628_Pancake_FR_004.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220628/20220628_Pancake_FR_005.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220628/20220628_Pancake_FR_003.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220628/20220628_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221107/2021107_Pancake_WM_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221107/2021107_Pancake_WM_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20230131/20230131_Pancake_WM_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20230131/20230131_Pancake_WM_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220729/20220729_Pancake_PG_Post_Tiz_01.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220729/20220729_Pancake_PG_Post_Tiz_02.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221024/20221024_Pancake_WIso_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20221024/20221024_Pancake_WIso_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220114/20220114_Pancake_FR_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220125/Pancake_20220125_PG_001.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220913/20220913_Pancake_FR_002.nev',\n",
       " '/Volumes/L_MillerLab/data/Pancake_20K3/Cerebus_data/20220913/20220913_Pancake_FR_001.nev']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cerebus_data_dict['Pancake_20K3']['nev_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1908016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields to obtain from nev files\n",
    "day_key = [] #done\n",
    "rec_time = [] #done\n",
    "task_id = [] # done\n",
    "duration = [] #done\n",
    "numChannels = [] #done\n",
    "hasBumps = [] #done\n",
    "numTrials = [] #done\n",
    "numReward = [] #done\n",
    "numAbort = [] #done\n",
    "numFail = [] #done\n",
    "numIncomplete = [] #done\n",
    "reward_size = [] #leave blank for now, fill in as we go through daily logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c510ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20200213_Greyson_Cage_016016.nev opened\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "strides is incompatible with shape of requested array and size of buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m nevobj \u001b[38;5;241m=\u001b[39m brpylib\u001b[38;5;241m.\u001b[39mNevFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Volumes/L_MillerLab/data/Greyson_17L2/CerebusData/20200213/20200213_Greyson_Cage_016016.nev\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnevobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43melec_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Jupyter_Notebooks/Miller_Lab/Database_Migration/Python_Utilities_Kev/brpylib/brpylib.py:638\u001b[0m, in \u001b[0;36mNevFile.getdata\u001b[0;34m(self, elec_ids, wave_read)\u001b[0m\n\u001b[1;32m    629\u001b[0m     tsBytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m    630\u001b[0m     ts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(\n\u001b[1;32m    631\u001b[0m         (nPackets,),\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_header[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBytesInDataPackets\u001b[39m\u001b[38;5;124m\"\u001b[39m],),\n\u001b[1;32m    636\u001b[0m     )\n\u001b[0;32m--> 638\u001b[0m PacketID \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnPackets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<H\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrawdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtsBytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_header\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBytesInDataPackets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# identify packet indices by type. if packet type is found, typecast rawdata into meaningful data arrays\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# neural and analog input data:\u001b[39;00m\n\u001b[1;32m    648\u001b[0m neuralPackets \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    649\u001b[0m     idx\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(PacketID)\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m NEURAL_PACKET_ID_MIN \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m element \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m NEURAL_PACKET_ID_MAX\n\u001b[1;32m    652\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: strides is incompatible with shape of requested array and size of buffer"
     ]
    }
   ],
   "source": [
    "# try opening in Matlab?\n",
    "nevobj = brpylib.NevFile('/Volumes/L_MillerLab/data/Greyson_17L2/CerebusData/20200213/20200213_Greyson_Cage_016016.nev')\n",
    "output = nevobj.getdata(elec_ids='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec3101f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22:53:24.758000'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(nevobj.basic_header['TimeOrigin'].time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b998d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** File given does exist, try again ***\n",
      "\n",
      "Enter complete .nev file path or hit enter to browse: \n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    nevobj = brpylib.NevFile(nev_list[i])\n",
    "    nevobj.basic_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007b9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20211214_Pancake__FR_001.nev opened\n",
      "\n",
      "20221103_Pancake_WI_001.nev opened\n",
      "\n",
      "20230214_Pancake_WM_002.nev opened\n",
      "\n",
      "20230214_Pancake_WM_003.nev opened\n",
      "\n",
      "20230214_Pancake_WM_001.nev opened\n"
     ]
    }
   ],
   "source": [
    "nevobjs = []\n",
    "outputs = []\n",
    "for fname in cerebus_data_dict['Pancake_20K3']['nev_list']:\n",
    "    nevobj = brpylib.NevFile(fname)\n",
    "    nevobjs.append(nevobj)\n",
    "    if ('FR' not in fname) and ('cage' not in fname.lower()):\n",
    "        output = nevobj.getdata(elec_ids='all')\n",
    "        outputs.append(output)\n",
    "    else:\n",
    "        outputs.append('None')\n",
    "        \n",
    "cerebus_data_dict['Pancake_20K3']['nevobjs'] = nevobjs\n",
    "cerebus_data_dict['Pancake_20K3']['outputs'] = outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016080a6",
   "metadata": {},
   "source": [
    "Cage and (most) free reaching data do not have digital_events field\n",
    "\n",
    "Ignore all task data for free reaching files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a4d6972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/20211214_Pancake__FR_001.nev               dict_keys(['digital_events'])\n",
      "/20221103_Pancake_WI_001.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20230214_Pancake_WM_002.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20230214_Pancake_WM_003.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20230214_Pancake_WM_001.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20210828_Pancake__FR_.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20220921_Pancake_PG_Post_Con_03.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20220921_Pancake_PG_Pre_Con_02.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20220921_Pancake_WS_Pre_Con_01.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20220921_Pancake_WS_Post_Con_04.nev               dict_keys(['spike_events', 'digital_events'])\n",
      "/20220920_Pancake_FR_001.nev               dict_keys(['spike_events'])\n",
      "/20220920_Pancake_FR_002.nev               dict_keys(['spike_events'])\n",
      "/20220920_Pancake_FR_003.nev               dict_keys(['spike_events'])\n",
      "/20220920_Pancake_FR_005.nev               dict_keys(['spike_events'])\n",
      "/20220920_Pancake_FR_004.nev               dict_keys(['spike_events'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs)):\n",
    "    output = outputs[i]\n",
    "    fname = nev_list[i][60:]\n",
    "    print(fname, '             ', output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1acc2f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181220_Greyson_FreeReaching_001.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n",
      "20181220_Greyson_PG_001.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n",
      "20181205_Greyson_PG_002.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n",
      "20181205_Greyson_PG_001.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n",
      "20200213_Greyson_Cage_003003.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n",
      "20200213_Greyson_Cage_005005.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n",
      "20200213_Greyson_Cage_010010.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n",
      "20200213_Greyson_Cage_004004.nev               dict_keys(['TimeStamps', 'Unit', 'Channel', 'Waveforms'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs)):\n",
    "    spike_events = outputs[i]['spike_events']\n",
    "    fname = nev_list[i][60:]\n",
    "    print(fname, '             ', spike_events.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17572033",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_nev_list = [nev_list[0]]\n",
    "for nev_filename in shortened_nev_list:\n",
    "    # open file\n",
    "    nevobj = brpylib.NevFile(nev_filename)\n",
    "    output = nevobj.getdata(elec_ids='all')\n",
    "    \n",
    "    # check that date in filename is same as date in basic header, if so append to day_key\n",
    "    filname_date = nev_filename[51:59]\n",
    "    dt = str(nevobj.basic_header['TimeOrigin'].date()).replace('-','')\n",
    "    assert filname_date == dt\n",
    "    #note that appending filename_date is a placeholder - should be of type int(11)\n",
    "    day_key.append(filename_date)\n",
    "    rec_time.append(str(nevobj.basic_header['TimeOrigin'].time()))\n",
    "    numChannels.append(len(set(output['spike_events']['Channel'])))\n",
    "    \n",
    "    unparsed_data_arr = np.array(output_pancake['digital_events']['UnparsedData'])\n",
    "    words = {'reward':0x20, 'abort': 0x21, 'fail': 0x22, 'incomp':0x23, 'trials':0x30}\n",
    "    words_count = {'reward':0, 'abort': 0, 'fail': 0, 'incomp':0, 'trials':0}\n",
    "    \n",
    "    for word,code in words.items():\n",
    "        n_events = np.sum(((unparsed_data_arr & 0xFF00) >> 8) == code)\n",
    "        words_count[word] += n_events\n",
    "    numReward.append(words_count['reward'])\n",
    "    numAbort.append(words_count['abort'])\n",
    "    numFail.append(words_count['fail'])\n",
    "    numIncomplete.append(words_count['incomp'])\n",
    "    numTrials.append(words_count['trials'])\n",
    "    \n",
    "    tasks = {0x01:'CO', 0x02:'RW', 0x03:'FC', 0x06:'MG', 0x07:'WF'}\n",
    "    task = tasks[np.unique((unparsed_data_arr[(unparsed_data_arr & 0xF000) == 0x1000] & 0x0F00) >> 8)[0]]\n",
    "    task_id.append(task)\n",
    "    \n",
    "    bumps = np.any((np.array(unparsed_data_arr) & 0xF000) == 0x5000)\n",
    "    hasBumps.append(bumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is set up using an SSH tunnel\n",
    "engine = create_engine(f\"mysql+pymysql://{userName}:{sesame}@127.0.0.1:3306/{dbName}\")\n",
    "\n",
    "log.to_sql('sessions', engine, index=False, if_exists=\"append\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
